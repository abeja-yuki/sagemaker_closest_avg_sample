{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "42b5e80b-ad1d-4335-a1f7-10a91127e3dc"
    }
   },
   "source": [
    "# Closest avg classification\n",
    "\n",
    "please visit for information\n",
    "https://github.com/abeja-yuki/sagemaker_closest_avg_sample\n",
    "\n",
    "Due to security problems, I hid some parts of my AWS information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "isConfigCell": true
   },
   "outputs": [],
   "source": [
    "bucket = '<my bucket name>'\n",
    "prefix = 'sagemaker/closest_avg'\n",
    " \n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b2548d66-6f8f-426f-9cda-7a3cd1459abd"
    }
   },
   "source": [
    "Now we'll import the Python libraries we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "bb88eea9-27f3-4e47-9133-663911ea09a9"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import sagemaker.amazon.common as smac\n",
    "import sagemaker\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "142777ae-c072-448e-b941-72bc75735d01"
    }
   },
   "source": [
    "---\n",
    "## Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "78105bc7-ce5d-4003-84f6-4dc5700c5945"
    }
   },
   "outputs": [],
   "source": [
    "v = 0.5 * np.random.random(1000) - 0.25 + 1.0\n",
    "labels = ['John Petrucci', 'Mike Mangini', 'Jordan Rudess', 'James LaBrie', 'John Myung']\n",
    "avg = [350, 450, 780, 280, 100]\n",
    "\n",
    "label_series = []\n",
    "feature_series = []\n",
    "\n",
    "for i in range(1000):\n",
    "    label_series.append(labels[i % 5])\n",
    "    feature_series.append(avg[i % 5] * v[i])\n",
    "\n",
    "df = pd.DataFrame({'label': label_series, 'feature': feature_series})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('label').agg({'feature': {'count': len, 'mean': np.mean}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b472326f-3584-4b61-aecc-04b35486a1ab"
    }
   },
   "source": [
    "And take a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "80c0adca-5db2-4152-a9f4-42cbc1dbde84"
    }
   },
   "outputs": [],
   "source": [
    "train_data_rate = 0.6\n",
    "evaluation_data_rate = 0.3\n",
    "\n",
    "train_data = df[:int(len(df) * train_data_rate)]\n",
    "validation_data = df[int(len(df) * train_data_rate):int(len(df) * (train_data_rate + evaluation_data_rate))]\n",
    "test_data = df[int(len(df) * (train_data_rate + evaluation_data_rate)):]\n",
    "\n",
    "\n",
    "print(len(train_data), len(validation_data), len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "ff9d10f9-b611-423b-80da-6dcdafd1c8b9"
    }
   },
   "source": [
    "Now, we'll convert the datasets to the recordIO-wrapped protobuf format used by the Amazon SageMaker algorithms and upload this data to S3.  We'll start with training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "buf = io.BytesIO()\n",
    "buf.write(pickle.dumps(train_data, 0))\n",
    "buf.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'closest_avg_train.data'\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(buf)\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll convert and upload the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "buf = io.BytesIO()\n",
    "buf.write(pickle.dumps(validation_data, 0))\n",
    "buf.seek(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'closest_avg_validation.data'\n",
    "boto3.resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation', key)).upload_fileobj(buf)\n",
    "s3_validation_data = 's3://{}/{}/validation/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "container = '{my account id}.dkr.ecr.us-east-2.amazonaws.com/sagemaker-closest-avg:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "linear = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.c4.xlarge',\n",
    "                                       output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                       sagemaker_session=sess)\n",
    "linear.set_hyperparameters(feature_dim=59,\n",
    "                           mini_batch_size=100,\n",
    "                           predictor_type='regressor',\n",
    "                           epochs=10,\n",
    "                           num_models=32,\n",
    "                           loss='absolute_loss')\n",
    "\n",
    "linear.fit({'training': s3_train_data, 'validation': s3_validation_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "2adcc348-9ab5-4a8a-8139-d0ecd740208a"
    }
   },
   "source": [
    "---\n",
    "## Host\n",
    "\n",
    "Now that we've trained the linear algorithm on our data, let's create a model and deploy that to a hosted endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_predictor = linear.deploy(initial_instance_count=1,\n",
    "                                 instance_type='ml.c4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_serializer = lambda data: pickle.dumps(data, 0)\n",
    "\n",
    "pickle_deserializer = lambda body, mime: pickle.loads(body.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_predictor.content_type = 'binary/octet-stream'\n",
    "linear_predictor.serializer = pickle_serializer\n",
    "linear_predictor.deserializer = pickle_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = linear_predictor.predict(test_data[['feature']])\n",
    "\n",
    "test_data['predicted'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "1.0 - len(test_data[test_data['label'] != test_data['predicted']]) / len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.Session().delete_endpoint(linear_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
